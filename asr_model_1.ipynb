{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting librosa\n",
      "  Using cached librosa-0.10.2.post1-py3-none-any.whl.metadata (8.6 kB)\n",
      "Collecting audioread>=2.1.9 (from librosa)\n",
      "  Using cached audioread-3.0.1-py3-none-any.whl.metadata (8.4 kB)\n",
      "Requirement already satisfied: numpy!=1.22.0,!=1.22.1,!=1.22.2,>=1.20.3 in d:\\anaconda\\lib\\site-packages (from librosa) (1.26.4)\n",
      "Requirement already satisfied: scipy>=1.2.0 in d:\\anaconda\\lib\\site-packages (from librosa) (1.13.1)\n",
      "Requirement already satisfied: scikit-learn>=0.20.0 in d:\\anaconda\\lib\\site-packages (from librosa) (1.4.2)\n",
      "Requirement already satisfied: joblib>=0.14 in d:\\anaconda\\lib\\site-packages (from librosa) (1.4.2)\n",
      "Requirement already satisfied: decorator>=4.3.0 in d:\\anaconda\\lib\\site-packages (from librosa) (5.1.1)\n",
      "Requirement already satisfied: numba>=0.51.0 in d:\\anaconda\\lib\\site-packages (from librosa) (0.59.1)\n",
      "Collecting soundfile>=0.12.1 (from librosa)\n",
      "  Downloading soundfile-0.13.1-py2.py3-none-win_amd64.whl.metadata (16 kB)\n",
      "Collecting pooch>=1.1 (from librosa)\n",
      "  Using cached pooch-1.8.2-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting soxr>=0.3.2 (from librosa)\n",
      "  Downloading soxr-0.5.0.post1-cp312-abi3-win_amd64.whl.metadata (5.6 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.1.1 in c:\\users\\avigy\\appdata\\roaming\\python\\python312\\site-packages (from librosa) (4.12.2)\n",
      "Requirement already satisfied: lazy-loader>=0.1 in d:\\anaconda\\lib\\site-packages (from librosa) (0.4)\n",
      "Requirement already satisfied: msgpack>=1.0 in d:\\anaconda\\lib\\site-packages (from librosa) (1.0.3)\n",
      "Requirement already satisfied: packaging in d:\\anaconda\\lib\\site-packages (from lazy-loader>=0.1->librosa) (23.2)\n",
      "Requirement already satisfied: llvmlite<0.43,>=0.42.0dev0 in d:\\anaconda\\lib\\site-packages (from numba>=0.51.0->librosa) (0.42.0)\n",
      "Requirement already satisfied: platformdirs>=2.5.0 in d:\\anaconda\\lib\\site-packages (from pooch>=1.1->librosa) (3.10.0)\n",
      "Requirement already satisfied: requests>=2.19.0 in d:\\anaconda\\lib\\site-packages (from pooch>=1.1->librosa) (2.32.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in d:\\anaconda\\lib\\site-packages (from scikit-learn>=0.20.0->librosa) (2.2.0)\n",
      "Requirement already satisfied: cffi>=1.0 in d:\\anaconda\\lib\\site-packages (from soundfile>=0.12.1->librosa) (1.16.0)\n",
      "Requirement already satisfied: pycparser in d:\\anaconda\\lib\\site-packages (from cffi>=1.0->soundfile>=0.12.1->librosa) (2.21)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in d:\\anaconda\\lib\\site-packages (from requests>=2.19.0->pooch>=1.1->librosa) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in d:\\anaconda\\lib\\site-packages (from requests>=2.19.0->pooch>=1.1->librosa) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in d:\\anaconda\\lib\\site-packages (from requests>=2.19.0->pooch>=1.1->librosa) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in d:\\anaconda\\lib\\site-packages (from requests>=2.19.0->pooch>=1.1->librosa) (2024.6.2)\n",
      "Using cached librosa-0.10.2.post1-py3-none-any.whl (260 kB)\n",
      "Using cached audioread-3.0.1-py3-none-any.whl (23 kB)\n",
      "Using cached pooch-1.8.2-py3-none-any.whl (64 kB)\n",
      "Downloading soundfile-0.13.1-py2.py3-none-win_amd64.whl (1.0 MB)\n",
      "   ---------------------------------------- 0.0/1.0 MB ? eta -:--:--\n",
      "   - -------------------------------------- 0.0/1.0 MB 1.3 MB/s eta 0:00:01\n",
      "   -- ------------------------------------- 0.1/1.0 MB 1.3 MB/s eta 0:00:01\n",
      "   -- ------------------------------------- 0.1/1.0 MB 1.3 MB/s eta 0:00:01\n",
      "   ------ --------------------------------- 0.2/1.0 MB 913.1 kB/s eta 0:00:01\n",
      "   -------- ------------------------------- 0.2/1.0 MB 1.2 MB/s eta 0:00:01\n",
      "   --------- ------------------------------ 0.2/1.0 MB 958.6 kB/s eta 0:00:01\n",
      "   ------------ --------------------------- 0.3/1.0 MB 1.1 MB/s eta 0:00:01\n",
      "   -------------- ------------------------- 0.4/1.0 MB 1.2 MB/s eta 0:00:01\n",
      "   ----------------- ---------------------- 0.4/1.0 MB 1.2 MB/s eta 0:00:01\n",
      "   ----------------- ---------------------- 0.4/1.0 MB 1.2 MB/s eta 0:00:01\n",
      "   ----------------- ---------------------- 0.4/1.0 MB 1.2 MB/s eta 0:00:01\n",
      "   ------------------- -------------------- 0.5/1.0 MB 983.0 kB/s eta 0:00:01\n",
      "   -------------------- ------------------- 0.5/1.0 MB 1.0 MB/s eta 0:00:01\n",
      "   -------------------- ------------------- 0.5/1.0 MB 1.0 MB/s eta 0:00:01\n",
      "   -------------------- ------------------- 0.5/1.0 MB 1.0 MB/s eta 0:00:01\n",
      "   --------------------- ------------------ 0.6/1.0 MB 807.6 kB/s eta 0:00:01\n",
      "   --------------------- ------------------ 0.6/1.0 MB 807.6 kB/s eta 0:00:01\n",
      "   --------------------- ------------------ 0.6/1.0 MB 807.6 kB/s eta 0:00:01\n",
      "   --------------------- ------------------ 0.6/1.0 MB 807.6 kB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 0.7/1.0 MB 837.2 kB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 0.7/1.0 MB 837.2 kB/s eta 0:00:01\n",
      "   --------------------------------- ------ 0.8/1.0 MB 910.7 kB/s eta 0:00:01\n",
      "   --------------------------------- ------ 0.8/1.0 MB 910.7 kB/s eta 0:00:01\n",
      "   --------------------------------- ------ 0.8/1.0 MB 910.7 kB/s eta 0:00:01\n",
      "   --------------------------------- ------ 0.8/1.0 MB 910.7 kB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.0/1.0 MB 896.8 kB/s eta 0:00:00\n",
      "Downloading soxr-0.5.0.post1-cp312-abi3-win_amd64.whl (164 kB)\n",
      "   ---------------------------------------- 0.0/164.9 kB ? eta -:--:--\n",
      "   --------- ------------------------------ 41.0/164.9 kB ? eta -:--:--\n",
      "   --------- ------------------------------ 41.0/164.9 kB ? eta -:--:--\n",
      "   ------------------------- ------------ 112.6/164.9 kB 939.4 kB/s eta 0:00:01\n",
      "   -------------------------------------  163.8/164.9 kB 984.6 kB/s eta 0:00:01\n",
      "   -------------------------------------- 164.9/164.9 kB 827.3 kB/s eta 0:00:00\n",
      "Installing collected packages: soxr, audioread, soundfile, pooch, librosa\n",
      "Successfully installed audioread-3.0.1 librosa-0.10.2.post1 pooch-1.8.2 soundfile-0.13.1 soxr-0.5.0.post1\n"
     ]
    }
   ],
   "source": [
    "!pip install librosa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import yaml\n",
    "\n",
    "\n",
    "class BaseModelConfigs:\n",
    "    def __init__(self):\n",
    "        self.model_path = None\n",
    "\n",
    "    def serialize(self):\n",
    "        class_attributes = {key: value\n",
    "                            for (key, value)\n",
    "                            in type(self).__dict__.items()\n",
    "                            if key not in ['__module__', '__init__', '__doc__', '__annotations__']}\n",
    "        instance_attributes = self.__dict__\n",
    "\n",
    "        # first init with class attributes then apply instance attributes overwriting any existing duplicate attributes\n",
    "        all_attributes = class_attributes.copy()\n",
    "        all_attributes.update(instance_attributes)\n",
    "\n",
    "        return all_attributes\n",
    "\n",
    "    def save(self, name: str = \"configs.yaml\"):\n",
    "        if self.model_path is None:\n",
    "            raise Exception(\"Model path is not specified\")\n",
    "\n",
    "        # create directory if not exist\n",
    "        if not os.path.exists(self.model_path):\n",
    "            os.makedirs(self.model_path)\n",
    "\n",
    "        with open(os.path.join(self.model_path, name), \"w\") as f:\n",
    "            yaml.dump(self.serialize(), f)\n",
    "\n",
    "    @staticmethod\n",
    "    def load(configs_path: str):\n",
    "        with open(configs_path, \"r\") as f:\n",
    "            configs = yaml.load(f, Loader=yaml.FullLoader)\n",
    "\n",
    "        config = BaseModelConfigs()\n",
    "        for key, value in configs.items():\n",
    "            setattr(config, key, value)\n",
    "\n",
    "        return config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "class ModelConfigs(BaseModelConfigs):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.model_path = os.path.join(\"Models/05_sound_to_text\", datetime.strftime(datetime.now(), \"%Y%m%d%H%M\"))\n",
    "        self.frame_length = 256 \n",
    "        self.frame_step = 160\n",
    "        self.fft_length = 384\n",
    "\n",
    "        self.vocab = \"abcdefghijklmnopqrstuvwxyz'?! \"\n",
    "        self.input_shape = None\n",
    "        self.max_text_length = None\n",
    "        self.max_spectrogram_length = None\n",
    "\n",
    "        self.batch_size = 8\n",
    "        self.learning_rate = 0.0005\n",
    "        self.train_epochs = 1000\n",
    "        self.train_workers = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import typing\n",
    "import importlib\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import logging\n",
    "\n",
    "def import_librosa(object) -> None:\n",
    "    \"\"\"Import librosa using importlib\"\"\"\n",
    "    try:\n",
    "        version = object.librosa.__version__\n",
    "    except:\n",
    "        version = \"librosa version not found\"\n",
    "        try:\n",
    "            object.librosa = importlib.import_module('librosa')\n",
    "            print(\"librosa version:\", object.librosa.__version__)\n",
    "        except:\n",
    "            raise ImportError(\"librosa is required to augment Audio. Please install it with `pip install librosa`.\")\n",
    "        \n",
    "class WavReader:\n",
    "    def __init__(self, frame_length, frame_step, fft_length,*args, **kwargs):\n",
    "        self.frame_length = frame_length\n",
    "        self.frame_step = frame_step\n",
    "        self.fft_length = fft_length\n",
    "        matplotlib.interactive(False)\n",
    "        import_librosa(self)\n",
    "    @staticmethod\n",
    "    def get_spectrogram(wav_path: str, frame_length: int, frame_step: int, fft_length: int) -> np.ndarray:\n",
    "        # audio, sr = librosa.load(file_path, sr=16000)\n",
    "        # spectrogram = librosa.feature.melspectrogram(y=audio, sr=sr, n_fft=self.fft_length, hop_length=self.frame_step, win_length=self.frame_length)\n",
    "        # return spectrogram\n",
    "        import_librosa(WavReader)\n",
    "        audio,orig=WavReader.librosa.load(wav_path)\n",
    "        spectrogram = WavReader.librosa.stft(audio,hop_length = frame_step,win_length=frame_length )\n",
    "        spectrogram = np.power(np.abs(spectrogram), 0.5)\n",
    "        spectrogram = (spectrogram - np.mean(spectrogram)) / (np.std(spectrogram) + 1e-10)\n",
    "\n",
    "        return spectrogram\n",
    "    \n",
    "    @staticmethod\n",
    "    def plot_audio(wav_path: str, title: str = None, sr: int = 16000) -> None:\n",
    "        import_librosa(WavReader)\n",
    "        audio, orig_sr = WavReader.librosa.load(wav_path, sr=sr)\n",
    "\n",
    "        duration = len(audio) / orig_sr\n",
    "\n",
    "        time = np.linspace(0, duration, num=len(audio))\n",
    "\n",
    "        plt.figure(figsize=(15, 5))\n",
    "        plt.plot(time, audio)\n",
    "        plt.title(title) if title else plt.title(\"Audio Plot\")\n",
    "        plt.ylabel(\"signal wave\")\n",
    "        plt.xlabel(\"time (s)\")\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "    @staticmethod\n",
    "    def plot_spectrogram(spectrogram: np.ndarray, title:str = \"\", transpose: bool = True, invert: bool = True) -> None:\n",
    "        if transpose:\n",
    "            spectrogram = spectrogram.T\n",
    "        \n",
    "        if invert:\n",
    "            spectrogram = spectrogram[::-1]\n",
    "\n",
    "        plt.figure(figsize=(15, 5))\n",
    "        plt.imshow(spectrogram, aspect=\"auto\", origin=\"lower\")\n",
    "        plt.title(f\"Spectrogram: {title}\")\n",
    "        plt.xlabel(\"Time\")\n",
    "        plt.ylabel(\"Frequency\")\n",
    "        plt.colorbar()\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "\n",
    "    def __call__(self, audio_path: str, label: typing.Any):\n",
    "        \"\"\"\n",
    "        Extract the spectrogram and label of a WAV file.\n",
    "\n",
    "        Args:\n",
    "            audio_path (str): Path to the WAV file.\n",
    "            label (typing.Any): Label of the WAV file.\n",
    "\n",
    "        Returns:\n",
    "            Tuple[np.ndarray, typing.Any]: Spectrogram of the WAV file and its label.\n",
    "        \"\"\"\n",
    "        return self.get_spectrogram(audio_path, self.frame_length, self.frame_step, self.fft_length), label\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TENSORFLOW SPECIFIC FUNCTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: onnx in c:\\users\\avigy\\appdata\\roaming\\python\\python312\\site-packages (1.17.0)\n",
      "Requirement already satisfied: numpy>=1.20 in d:\\anaconda\\lib\\site-packages (from onnx) (1.26.4)\n",
      "Requirement already satisfied: protobuf>=3.20.2 in c:\\users\\avigy\\appdata\\roaming\\python\\python312\\site-packages (from onnx) (3.20.3)\n"
     ]
    }
   ],
   "source": [
    "!pip install onnx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\avigy\\AppData\\Roaming\\Python\\Python312\\site-packages\\tf2onnx\\tf_loader.py:68: The name tf.reset_default_graph is deprecated. Please use tf.compat.v1.reset_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\avigy\\AppData\\Roaming\\Python\\Python312\\site-packages\\tf2onnx\\tf_loader.py:72: The name tf.train.import_meta_graph is deprecated. Please use tf.compat.v1.train.import_meta_graph instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from keras.callbacks import Callback\n",
    "import tf2onnx\n",
    "import logging\n",
    "import onnx\n",
    "class CTCloss(tf.keras.losses.Loss):\n",
    "    def __init__(self,name:str=\"CTCloss\"):\n",
    "        super(CTCloss,self).__init__()\n",
    "        self.name = name\n",
    "        self.loss_fn = tf.keras.backend.ctc_batch_cost\n",
    "    def __call__(self,y_true:tf.Tensor,y_pred:tf.Tensor,sample_weight=None)->tf.Tensor:\n",
    "        batch_len = tf.cast(tf.shape(y_true)[0],dtype = \"int64\")\n",
    "        label_len = tf.cast(tf.shape(y_true)[1], dtype=\"int64\")*tf.ones(shape=(batch_len,1),dtype=\"int64\")\n",
    "        input_len= tf.cast(tf.shape(y_pred)[1], dtype=\"int64\")*tf.ones(shape=(batch_len,1),dtype=\"int64\")\n",
    "        loss = self.loss_fn(y_true,y_pred,input_len,label_len)\n",
    "        return loss\n",
    "    \n",
    "class Model2Onnx(Callback):\n",
    "    def __init__(self,saved_model_path:str,metadata:dict=None,save_on_epoch_end:bool=False)->None:\n",
    "        super().__init__()\n",
    "        self.saved_model_path = saved_model_path\n",
    "        self.metadata = metadata\n",
    "        self.save_on_epoch_end = save_on_epoch_end\n",
    "\n",
    "    @staticmethod\n",
    "    def model2onnx(model:tf.keras.Model,onnx_model_path:str):\n",
    "        tf2onnx.convert.from_keras(model,output_path=onnx_model_path)\n",
    "\n",
    "    @staticmethod\n",
    "    def add_metadata(onnx_model_path:str,metadata:dict=None):\n",
    "        onnx_model  = onnx.load(onnx_model_path)\n",
    "        for key,val in metadata.items():\n",
    "            meta = onnx_model.metadata_props.add()\n",
    "            meta.key = key\n",
    "            meta.value = str(val)\n",
    "        onnx.save(onnx_model,onnx_model_path)\n",
    "\n",
    "\n",
    "    def epoch_end(self, epoch: int, logs: dict=None):\n",
    "        \"\"\" Converts the model to onnx format on every epoch end. \"\"\"\n",
    "        if self.save_on_epoch_end:\n",
    "            self.on_train_end(logs=logs)\n",
    "\n",
    "    def train_end(self, logs=None):\n",
    "        \"\"\" Converts the model to onnx format after training is finished. \"\"\"\n",
    "        self.model.load_weights(self.saved_model_path)\n",
    "        onnx_model_path = self.saved_model_path.replace(\".h5\", \".onnx\")\n",
    "        self.model2onnx(self.model, onnx_model_path)\n",
    "        self.include_metadata(onnx_model_path, self.metadata)\n",
    "\n",
    "class TrainLogger(Callback):\n",
    "    def __init__(self,log_path:str,log_level:int=logging.INFO,console_output:bool=False)->None:\n",
    "        super().__init__()\n",
    "        self.log_path = log_path\n",
    "        self.log_level = log_level\n",
    "        self.logger = logging.getLogger(__name__)\n",
    "        self.logger.setLevel(self.log_level)\n",
    "        self.file_handler.setFormatter(self.formatter)\n",
    "\n",
    "        if not console_output:\n",
    "            self.logger.handlers[:] = []\n",
    "        self.logger.addHandler(logging.FileHandler(self.log_path))\n",
    "\n",
    "    def on_epoch_end(self, epoch: int, logs: dict=None):\n",
    "        epoch_message = f\"Epoch {epoch}; \"\n",
    "        logs_message = \"; \".join([f\"{key}: {value}\" for key, value in logs.items()])\n",
    "        self.logger.info(epoch_message + logs_message)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transformer:\n",
    "    def __init__(self, log_level: int = logging.INFO) -> None:\n",
    "        self._log_level = log_level\n",
    "\n",
    "        self.logger = logging.getLogger(self.__class__.__name__)\n",
    "        self.logger.setLevel(logging.INFO)\n",
    "\n",
    "    def __call__(self, data: typing.Any, label: typing.Any, *args, **kwargs):\n",
    "        raise NotImplementedError\n",
    "class LabelTransformer(Transformer):\n",
    "    def __init__(self, vocab: typing.List[str]):\n",
    "        self.vocab = vocab\n",
    "    def __call__(self, data: np.array, label: np.array):\n",
    "        return data, np.array([self.vocab.index(l) for l in label if l in self.vocab])\n",
    "\n",
    "class LabelPadding(Transformer):\n",
    "    def __init__(self, padding_value: int,\n",
    "        max_word_length: int = None, \n",
    "        use_on_batch: bool = False):\n",
    "        self.max_text_length = max_word_length\n",
    "        self.padding_value = padding_value\n",
    "        self.use_on_batch = use_on_batch\n",
    "\n",
    "        if not use_on_batch and max_word_length is None:\n",
    "            raise ValueError(\"max_word_length must be specified if use_on_batch is False\")\n",
    "\n",
    "    def __call__(self, data: typing.Any, label: typing.Any, *args, **kwargs):\n",
    "\n",
    "        if self.use_on_batch:\n",
    "            max_len = max([len(a) for a in label])\n",
    "            padded_labels=[]\n",
    "            for l in label:\n",
    "                padded_label=np.pad(l, (0, max_len - len(l)), mode=\"constant\", constant_values=self.padding_value)\n",
    "                padded_labels.append(padded_label)\n",
    "            padded_labels=np.array(padded_labels)\n",
    "            return data,padded_labels\n",
    "        label =label[:self.max_word_length]\n",
    "        return data,np.pad(label, (0, self.max_word_length - len(label)), mode=\"constant\", constant_values=self.padding_value)\n",
    "\n",
    "class SpectrogramPadding(Transformer):\n",
    "    def __init__(self, max_spectrogram_length: int, max_text_length: int):\n",
    "        self.max_spectrogram_length = max_spectrogram_length\n",
    "        self.max_text_length = max_text_length\n",
    "    def __call__(self, data: typing.Any, label: typing.Any, *args, **kwargs):\n",
    "        return data, self.transform(label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = \"./LJSpeech-1.1\"\n",
    "metadata_path = dataset_path + \"/metadata.csv\"\n",
    "wavs_path = dataset_path + \"/wavs/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_name</th>\n",
       "      <th>normalized_transcription</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LJ001-0001</td>\n",
       "      <td>Printing, in the only sense with which we are ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LJ001-0002</td>\n",
       "      <td>in being comparatively modern.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LJ001-0003</td>\n",
       "      <td>For although the Chinese took impressions from...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LJ001-0004</td>\n",
       "      <td>produced the block books, which were the immed...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LJ001-0005</td>\n",
       "      <td>the invention of movable metal letters in the ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    file_name                           normalized_transcription\n",
       "0  LJ001-0001  Printing, in the only sense with which we are ...\n",
       "1  LJ001-0002                     in being comparatively modern.\n",
       "2  LJ001-0003  For although the Chinese took impressions from...\n",
       "3  LJ001-0004  produced the block books, which were the immed...\n",
       "4  LJ001-0005  the invention of movable metal letters in the ..."
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from urllib.request import urlopen\n",
    "\n",
    "metadata_df = pd.read_csv(metadata_path, sep=\"|\", header=None, quoting=3)\n",
    "metadata_df.columns = [\"file_name\", \"transcription\", \"normalized_transcription\"]\n",
    "metadata_df = metadata_df[[\"file_name\", \"normalized_transcription\"]]\n",
    "metadata_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "try: [tf.config.experimental.set_memory_growth(gpu, True) for gpu in tf.config.experimental.list_physical_devices(\"GPU\")]\n",
    "except: pass\n",
    "\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau, TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13100/13100 [08:39<00:00, 25.21it/s]\n"
     ]
    }
   ],
   "source": [
    "dataset = [[f\"./LJSpeech-1.1/wavs/{file}.wav\", label] for file, label in metadata_df.values.tolist()]\n",
    "configs = ModelConfigs()\n",
    "\n",
    "max_text_len, max_spectrogram_length = 0, 0\n",
    "for file_path, label in tqdm(dataset):\n",
    "    spectrogram = WavReader.get_spectrogram(file_path,frame_length=configs.frame_length,frame_step=configs.frame_step,fft_length=configs.fft_length)\n",
    "    valid_label=[c for c in label if c in configs.vocab]\n",
    "    max_text_len = max(max_text_len,len(valid_label))\n",
    "    max_spectrogram_length = max(max_spectrogram_length,spectrogram.shape[0])\n",
    "    configs.input_shape = [max_spectrogram_length,spectrogram.shape[1]]\n",
    "configs.max_spectrogram_length = max_spectrogram_length\n",
    "configs.max_text_length = max_text_len\n",
    "configs.save()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting onnx==1.16.1\n",
      "  Downloading onnx-1.16.1-cp312-cp312-win_amd64.whl.metadata (16 kB)\n",
      "Requirement already satisfied: numpy>=1.20 in d:\\anaconda\\lib\\site-packages (from onnx==1.16.1) (1.26.4)\n",
      "Requirement already satisfied: protobuf>=3.20.2 in c:\\users\\avigy\\appdata\\roaming\\python\\python312\\site-packages (from onnx==1.16.1) (3.20.3)\n",
      "Downloading onnx-1.16.1-cp312-cp312-win_amd64.whl (14.4 MB)\n",
      "   ---------------------------------------- 0.0/14.4 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.1/14.4 MB 2.6 MB/s eta 0:00:06\n",
      "    --------------------------------------- 0.2/14.4 MB 2.2 MB/s eta 0:00:07\n",
      "   - -------------------------------------- 0.4/14.4 MB 3.2 MB/s eta 0:00:05\n",
      "   - -------------------------------------- 0.7/14.4 MB 3.8 MB/s eta 0:00:04\n",
      "   -- ------------------------------------- 0.8/14.4 MB 3.6 MB/s eta 0:00:04\n",
      "   -- ------------------------------------- 0.9/14.4 MB 3.6 MB/s eta 0:00:04\n",
      "   --- ------------------------------------ 1.2/14.4 MB 4.0 MB/s eta 0:00:04\n",
      "   ---- ----------------------------------- 1.5/14.4 MB 4.1 MB/s eta 0:00:04\n",
      "   ---- ----------------------------------- 1.8/14.4 MB 4.3 MB/s eta 0:00:03\n",
      "   ----- ---------------------------------- 2.0/14.4 MB 4.5 MB/s eta 0:00:03\n",
      "   ----- ---------------------------------- 2.1/14.4 MB 4.4 MB/s eta 0:00:03\n",
      "   ----- ---------------------------------- 2.1/14.4 MB 4.4 MB/s eta 0:00:03\n",
      "   ----- ---------------------------------- 2.1/14.4 MB 4.4 MB/s eta 0:00:03\n",
      "   ----- ---------------------------------- 2.1/14.4 MB 4.4 MB/s eta 0:00:03\n",
      "   ----- ---------------------------------- 2.1/14.4 MB 4.4 MB/s eta 0:00:03\n",
      "   ----- ---------------------------------- 2.1/14.4 MB 4.4 MB/s eta 0:00:03\n",
      "   ----- ---------------------------------- 2.1/14.4 MB 4.4 MB/s eta 0:00:03\n",
      "   ------ --------------------------------- 2.4/14.4 MB 2.8 MB/s eta 0:00:05\n",
      "   ------- -------------------------------- 2.6/14.4 MB 3.0 MB/s eta 0:00:04\n",
      "   ------- -------------------------------- 2.9/14.4 MB 3.1 MB/s eta 0:00:04\n",
      "   -------- ------------------------------- 3.2/14.4 MB 3.2 MB/s eta 0:00:04\n",
      "   --------- ------------------------------ 3.3/14.4 MB 3.2 MB/s eta 0:00:04\n",
      "   --------- ------------------------------ 3.5/14.4 MB 3.4 MB/s eta 0:00:04\n",
      "   ---------- ----------------------------- 3.8/14.4 MB 3.4 MB/s eta 0:00:04\n",
      "   ----------- ---------------------------- 4.1/14.4 MB 3.5 MB/s eta 0:00:03\n",
      "   ----------- ---------------------------- 4.2/14.4 MB 3.6 MB/s eta 0:00:03\n",
      "   ----------- ---------------------------- 4.2/14.4 MB 3.6 MB/s eta 0:00:03\n",
      "   ----------- ---------------------------- 4.2/14.4 MB 3.6 MB/s eta 0:00:03\n",
      "   ------------ --------------------------- 4.5/14.4 MB 3.3 MB/s eta 0:00:03\n",
      "   ------------- -------------------------- 4.8/14.4 MB 3.4 MB/s eta 0:00:03\n",
      "   -------------- ------------------------- 5.1/14.4 MB 3.5 MB/s eta 0:00:03\n",
      "   --------------- ------------------------ 5.4/14.4 MB 3.6 MB/s eta 0:00:03\n",
      "   --------------- ------------------------ 5.7/14.4 MB 3.7 MB/s eta 0:00:03\n",
      "   ---------------- ----------------------- 6.0/14.4 MB 3.8 MB/s eta 0:00:03\n",
      "   ----------------- ---------------------- 6.3/14.4 MB 3.8 MB/s eta 0:00:03\n",
      "   ----------------- ---------------------- 6.3/14.4 MB 3.8 MB/s eta 0:00:03\n",
      "   ----------------- ---------------------- 6.3/14.4 MB 3.8 MB/s eta 0:00:03\n",
      "   ----------------- ---------------------- 6.4/14.4 MB 3.6 MB/s eta 0:00:03\n",
      "   ------------------ --------------------- 6.8/14.4 MB 3.7 MB/s eta 0:00:03\n",
      "   ------------------- -------------------- 7.0/14.4 MB 3.7 MB/s eta 0:00:02\n",
      "   -------------------- ------------------- 7.4/14.4 MB 3.8 MB/s eta 0:00:02\n",
      "   --------------------- ------------------ 7.7/14.4 MB 3.9 MB/s eta 0:00:02\n",
      "   ---------------------- ----------------- 8.0/14.4 MB 3.9 MB/s eta 0:00:02\n",
      "   ---------------------- ----------------- 8.2/14.4 MB 4.0 MB/s eta 0:00:02\n",
      "   ----------------------- ---------------- 8.4/14.4 MB 4.0 MB/s eta 0:00:02\n",
      "   ----------------------- ---------------- 8.4/14.4 MB 4.0 MB/s eta 0:00:02\n",
      "   ----------------------- ---------------- 8.4/14.4 MB 4.0 MB/s eta 0:00:02\n",
      "   ----------------------- ---------------- 8.4/14.4 MB 4.0 MB/s eta 0:00:02\n",
      "   ----------------------- ---------------- 8.4/14.4 MB 4.0 MB/s eta 0:00:02\n",
      "   ----------------------- ---------------- 8.5/14.4 MB 3.6 MB/s eta 0:00:02\n",
      "   ------------------------ --------------- 8.8/14.4 MB 3.7 MB/s eta 0:00:02\n",
      "   ------------------------ --------------- 9.0/14.4 MB 3.7 MB/s eta 0:00:02\n",
      "   ------------------------- -------------- 9.2/14.4 MB 3.7 MB/s eta 0:00:02\n",
      "   -------------------------- ------------- 9.5/14.4 MB 3.7 MB/s eta 0:00:02\n",
      "   -------------------------- ------------- 9.7/14.4 MB 3.8 MB/s eta 0:00:02\n",
      "   --------------------------- ------------ 9.9/14.4 MB 3.8 MB/s eta 0:00:02\n",
      "   ---------------------------- ----------- 10.2/14.4 MB 3.8 MB/s eta 0:00:02\n",
      "   ---------------------------- ----------- 10.4/14.4 MB 3.9 MB/s eta 0:00:02\n",
      "   ----------------------------- ---------- 10.5/14.4 MB 3.9 MB/s eta 0:00:02\n",
      "   ----------------------------- ---------- 10.5/14.4 MB 3.9 MB/s eta 0:00:02\n",
      "   ----------------------------- ---------- 10.5/14.4 MB 3.9 MB/s eta 0:00:02\n",
      "   ----------------------------- ---------- 10.5/14.4 MB 3.9 MB/s eta 0:00:02\n",
      "   ----------------------------- ---------- 10.5/14.4 MB 3.9 MB/s eta 0:00:02\n",
      "   ----------------------------- ---------- 10.5/14.4 MB 3.9 MB/s eta 0:00:02\n",
      "   ----------------------------- ---------- 10.5/14.4 MB 3.9 MB/s eta 0:00:02\n",
      "   ----------------------------- ---------- 10.5/14.4 MB 3.9 MB/s eta 0:00:02\n",
      "   ----------------------------- ---------- 10.5/14.4 MB 3.9 MB/s eta 0:00:02\n",
      "   ----------------------------- ---------- 10.5/14.4 MB 3.9 MB/s eta 0:00:02\n",
      "   ----------------------------- ---------- 10.5/14.4 MB 3.9 MB/s eta 0:00:02\n",
      "   ----------------------------- ---------- 10.5/14.4 MB 3.9 MB/s eta 0:00:02\n",
      "   ----------------------------- ---------- 10.5/14.4 MB 3.9 MB/s eta 0:00:02\n",
      "   ----------------------------- ---------- 10.5/14.4 MB 3.9 MB/s eta 0:00:02\n",
      "   ----------------------------- ---------- 10.5/14.4 MB 3.9 MB/s eta 0:00:02\n",
      "   ----------------------------- ---------- 10.5/14.4 MB 3.9 MB/s eta 0:00:02\n",
      "   ----------------------------- ---------- 10.5/14.4 MB 3.9 MB/s eta 0:00:02\n",
      "   ----------------------------- ---------- 10.5/14.4 MB 3.9 MB/s eta 0:00:02\n",
      "   ----------------------------- ---------- 10.5/14.4 MB 3.0 MB/s eta 0:00:02\n",
      "   ----------------------------- ---------- 10.7/14.4 MB 3.0 MB/s eta 0:00:02\n",
      "   ------------------------------ --------- 11.1/14.4 MB 3.0 MB/s eta 0:00:02\n",
      "   ------------------------------- -------- 11.4/14.4 MB 3.0 MB/s eta 0:00:02\n",
      "   -------------------------------- ------- 11.7/14.4 MB 3.0 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 12.0/14.4 MB 3.0 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 12.4/14.4 MB 3.4 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 12.6/14.4 MB 3.4 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 12.6/14.4 MB 3.4 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 12.6/14.4 MB 3.4 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 12.6/14.4 MB 3.4 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 12.6/14.4 MB 3.4 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 12.6/14.4 MB 3.4 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 12.6/14.4 MB 3.4 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 12.7/14.4 MB 3.0 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 13.1/14.4 MB 3.0 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 13.3/14.4 MB 3.0 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 13.6/14.4 MB 3.0 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 13.8/14.4 MB 3.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------  14.1/14.4 MB 3.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------  14.4/14.4 MB 3.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 14.4/14.4 MB 3.1 MB/s eta 0:00:00\n",
      "Installing collected packages: onnx\n",
      "  Attempting uninstall: onnx\n",
      "    Found existing installation: onnx 1.17.0\n",
      "    Uninstalling onnx-1.17.0:\n",
      "      Successfully uninstalled onnx-1.17.0\n",
      "Successfully installed onnx-1.16.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: The scripts backend-test-tools.exe, check-model.exe and check-node.exe are installed in 'C:\\Users\\avigy\\AppData\\Roaming\\Python\\Python312\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n"
     ]
    }
   ],
   "source": [
    "data_provider = DataProvider(dataset,configs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
